---
weight: 50
title: Alarms generated by the Apama-ctrl microservice
layout: redirect
---

Alarms are created by user applications in the {{< product-c8y-iot >}} tenant (for example, by an analytic model, an activated EPL file, or a smart rule). To learn about alarms in general, refer to [Working with alarms](/device-management-application/monitoring-and-controlling-devices/#working-with-alarms). The Apama-ctrl microservice also generates alarms because it has encountered some problem, so that the user is notified about the situation. The information below is about alarms that are generated by the Apama-ctrl microservice, their causes, consequences and possible ways to resolve them.

{{< c8y-admon-info >}}
Alarms generated by Apama-ctrl about its own state are available as of Analytics Builder 10.5.0 and EPL Apps 10.5.0.
{{< /c8y-admon-info >}}

 You can view alarms in the following ways:

1. In the Cockpit application. See [Cockpit](/cockpit/) for detailed information.
2. In the Administration application, under **Ecosystem** > **Microservices**. Click the Apama-ctrl microservice and then click **Status**.
   See [Monitoring microservices](/standard-tenant/ecosystem/#monitoring-microservices) for detailed information.
3. From the Streaming Analytics application. Click the **Diagnostics** (or **Enhanced**) link which is provided at the bottom of the home screen. A ZIP file is then downloaded that contains alarms information under */alarm/alarms_apama-ctrl-object.json*. See [Downloading diagnostics and logs](#diagnostics-download) for detailed information.

### Alarm severities {#alarm-severities}

| Severity | Description                                                  |
| -------- | ------------------------------------------------------------ |
| CRITICAL | Apama-ctrl was unable to continue running the user's applications and will require corrective action. |
| MAJOR    | Apama-ctrl has encountered a situation that will result in some loss of service (for example, due to a restart). |
| MINOR    | Apama-ctrl has a problem that you might want to fix.         |
| WARNING  | There is a warning.                                          |

### Alarms created by the Apama-ctrl microservice {#alarms-created-by-the-apama-ctrl-microservice}

Apama-ctrl can create alarms to notify users in scenarios such as the correlator running out of memory, uncaught exceptions in activated EPL files, and so on. Once you see an alarm in the {{< product-c8y-iot >}} tenant, you should diagnose it and resolve it depending on the severity level of the raised alarm. Each alarm has details such as title, text, type, date, and count (represents the number of times the alarm has been raised).

The following is a list of the alarms. The information further down below explains when these alarms will occur, their consequences, and how to resolve them.

- [Change in tenant options and restart of Apama-ctrl](#tenant_option_change)
- [Safe mode on startup](#apama_safe_mode)
- [Deactivating models in the Apama-ctrl-starter microservice](#apama_ctrl_starter)
- [High memory usage](#high-memory-usage)
- [Warning or higher level logging from an EPL file](#apama_ctrl_fatalcritwarn)
- [An EPL file throws an uncaught exception](#apama_ctrl_error)
- [An EPL app is running in an infinite or long-running loop](#apama_ctrl_warn)
- [EPL app restore timeout on restart of Apama-ctrl](#eplapp_restore_timeout)
- [Multiple extensions with the same name](#extension_error)
- [Smart rule configuration failed](#smart-rule-configuration-failed)
- [Smart rule restore failed](#smart-rule-restore-failed)
- [Connection to correlator lost](#connection-to-correlator-lost)
- [Performance alarms](#performance-alarms)
- [Parent tenant not subscribed](#parent-tenant-not-subscribed)

Once the cause of an alarm is resolved, you must acknowledge and clear the alarm in the {{< product-c8y-iot >}} tenant. Otherwise, you will continue to see the alarm until a further restart of the Apama-ctrl microservice.

{{< c8y-admon-info >}}
The alarm texts for the alarms below may undergo minor changes in the future.
{{< /c8y-admon-info >}}


#### Change in tenant options and restart of Apama-ctrl {#tenant_option_change}

This alarm is raised when a tenant option changes in the `analytics.builder` or `streaminganalytics` category. For details on the tenant options, refer to the [Tenant API](https://{{< domain-c8y >}}/api/core/#tag/Tenant-API) in the {{< openapi >}} for more details.

- Alarm type: `tenant_option_change`
- Alarm text: Detected changes in tenant option. Apama-ctrl will restart in order to use it.
- Alarm severity: MAJOR

Analytics Builder allows you to configure its settings by changing the tenant options, using key names such as `numWorkerThreads` or `status_device_name`. For example, if you want to process things in parallel, you can set `numWorkerThreads` to 3 by sending a REST request to {{< product-c8y-iot >}}, which will update the tenant option. Such a change automatically restarts the Apama-ctrl microservice. To notify the users about the restart, Apama-ctrl raises an alarm, saying that changes have been detected in a tenant option and that Apama-ctrl will restart in order to use it.

Once you see this alarm, you can be sure that your change is effective.


#### Safe mode on startup {#apama_safe_mode}

This alarm is raised whenever the Apama-ctrl microservice switches to safe mode.

- Alarm type: `apama_safe_mode`
- Alarm text: Apama-ctrl appears to be repeatedly restarting. As a precaution, user-provided EPL, analytic models and extensions that might have caused this have been disabled. Refer to the audit log for more details. Please check any recent alarms, or contact support or your administrator.
- Alarm severity: CRITICAL

Apama-ctrl detects if it has been repeatedly restarting and if user assets (EPL apps, analytic models, extensions) have been modified recently. Apama-ctrl disables all user assets as a precaution. Potential causes are, for example, an EPL app that consumes more memory than is available or an extension containing bugs.

You can check the mode of the microservice (either normal or safe mode) by making a REST request to *service/cep/diagnostics/apamaCtrlStatus* (available as of EPL Apps 10.5.7 and Analytics Builder 10.5.7), which contains a `safe_mode` flag in its response.

To diagnose the cause of an unexpected restart, you can try the following:

- Check the EPL apps memory profiler by making a REST request to */service/cep/diagnostics/eplMemoryProfiler* (available as of EPL Apps 10.5.7) for any memory leaks.

    Note that you must re-activate the EPL apps that were active before as the Apama-ctrl microservice loses information about the previous microservice instance when it restarts due to safe mode. To replicate the previous scenario, run the EPL apps and process some events to trigger a leak and then use the memory profiler to check for any memory leaks.

- Check the microservice logs for any exceptions by downloading the diagnostics overview ZIP file as described in [Downloading diagnostics and logs](#diagnostics-download). In the downloaded ZIP file, you can find the logs under */diagnostics/*.

    As mentioned in the above point, re-activate the EPL apps and analytic models that were active before and then check the logs.

- Check the audit logs. The audit logs are accessible via the Administration application and the audit API.
See [Audit logs](/standard-tenant/audit-logs) and
[Audit API](https://{{< domain-c8y >}}/api/core/#tag/Audit-API) in the {{< openapi >}} for details of accessing the audit logs.

In safe mode, all previously active analytic models and EPL apps are deactivated and must be manually re-activated.


#### Deactivating models in the Apama-ctrl-starter microservice {#apama_ctrl_starter}

This alarm is raised when Apama-ctrl switches from the fully capable microservice to the Apama-ctrl-starter microservice with more than 3 active models.

- Alarm type: `apama_ctrl_starter`
- Alarm text: The following models were de-activated as Analytics Builder is restricted to &lt;activate limit&gt; active models: (&lt;models&gt;).
- Alarm severity: MINOR

With the Apama-ctrl-starter microservice, a user can have a maximum of 3 active models. For example, a user is working with the fully capable Apama-ctrl microservice and has 5 active models, and then switches to Apama-ctrl-starter. Since Apama-ctrl-starter does not allow more than 3 active models, it deactivates all the active models (5) and raises an alarm to notify the user.


#### High memory usage {#high-memory-usage}

This alarm is raised whenever the Apama-ctrl microservice consumes 90% of the maximum memory permitted for the microservice container. During this time, the Apama-ctrl microservice automatically generates the diagnostics overview ZIP file which contains diagnostics information used for identifying the most likely cause for memory consumption.

There are 3 variants of this alarm, depending on the time and count restrictions of the generated diagnostics overview ZIP file.

First variant:

- Alarm type: `apama_highmemoryusage`
- Alarm text: Streaming Analytics is using 90% of available memory (&lt;totalMemory&gt;). Your apps will be in danger of crashing. Diagnostics file is located at &lt;URL-to-ZIP-file&gt; You can also download the file by navigating to Administration > Management > Files Repository
- Alarm severity: WARNING

Second variant:

- Alarm type: `apama_highmemoryusage`
- Alarm text: Streaming Analytics is using 90% of available memory (&lt;totalMemory&gt;). Your apps will be in danger of crashing. Have recently created diagnostics snapshot (within last hour).
- Alarm severity: WARNING

Third variant:

- Alarm type: `apama_highmemoryusage`
- Alarm text: Streaming Analytics is using 90% of available memory (&lt;totalMemory&gt;). Your apps will be in danger of crashing. Have created 5 diagnostics snapshots, not creating any more, refer to past alarms.
- Alarm severity: WARNING

Running EPL apps (and to a lesser extent, smart rules and analytic models) consumes memory, the amount will depend a lot on the nature of the app running. The memory usage should be approximately constant for a given set of apps, but it is possible to create a "memory leak", particularly in an EPL file or a custom block. The Apama-ctrl microservice monitors memory and raises an alarm with WARNING severity if the 90% memory limit is reached along with the diagnostics overview ZIP file and saves it to the files repository (as mentioned in the alarm text).

Apama-ctrl generates the diagnostics overview ZIP files with the following conditions:

- Only if it has not been generated in the last 1 hour.
- A maximum of 5 diagnostics overview ZIP files from its start time until it stops.
- Overall, it can generate a maximum of 20 ZIP files per {{< product-c8y-iot >}} tenant, beyond which it keeps deleting the oldest ZIP files during its startup process.

To diagnose high-memory-consuming models and EPL apps, you can try the following (it could be listener leaks, excessive state being stored or spawned monitors leaking, and so on):

- Download the automatically generated diagnostics overview ZIP file (refer to the alarm text for its location) and look at *correlator/inspect.json* and *correlator/status.json* for the number of listeners. This number may be large in the case of a listener leak. Note that this ZIP file includes the EPL memory profiler snapshots.

- Download the diagnostics information from the Streaming Analytics application using the **Diagnostics** link (as described in [Downloading diagnostics and logs](#diagnostics-download)). The EPL memory profiler from the **Diagnostics** link in */diagnostics/eplMemoryProfiler.csv* gives the memory consumed by each monitor along with details such as the number of listeners or the number of monitor instances running something like shown in the snippet below. This can help you to understand which monitor is consuming more memory and try to reduce it.

    | Monitor | Monitor instances | EPL objects | Listeners | Bytes   | Overhead bytes |
    | ------- | ----------------- | ----------- | --------- | ------- | -------------- |
    | mon1    | 1                 | 5384        | 4         | 1073908 | 383240         |
    | mon2    | 1                 | 2           | 2         | 696     | 2280           |
    | mon3    | 1                 | 4           | 1         | 840     | 752            |

- When using the **Enhanced** link in the Streaming Analytics application, the diagnostics information includes, in addition to the information that you get with the **Diagnostics** link, requests that are more resource-intensive and may significantly slow down the correlator. This includes the contents of the queues. So when diagnosing the cause for the first time, it is recommended to use the overview ZIP file from the **Diagnostics** link, unless additional information is required.

- Also check for memory usage on all the input and output queues available from the **Enhanced** link in */diagnostics/toStringQueues.txt*.

If the memory continues to grow, then when it reaches the limit, the correlator will run out of memory and Apama-ctrl will shut down. To prevent the microservice from going down, you must fix this as a priority.

See also [Diagnostic tools for Apama in Cumulocity IoT](https://techcommunity.softwareag.com/techniques-blog/-/blogs/apama-in-cumulocity-iot) in {{< company-sag >}}'s {{< sag-dev-community >}}.


#### Warning or higher level logging from an EPL file {#apama_ctrl_fatalcritwarn}

This alarm is raised whenever messages are logged by EPL files with specific log levels (including CRITICAL, FATAL, ERROR and WARNING).

The Streaming Analytics application allows you to deploy EPL files to the correlator. The Apama-ctrl microservice analyzes logged content in the EPL files and raises an alarm for specific log levels with details such as monitor name, log text and alarm type (either of WARNING or MAJOR), based on the log level.

For example, the following is a simple monitor which prints a sequence and logs some texts at different EPL log levels.

```java
monitor Sample{
   action onload() {
      log "Info"; // default log level is now INFO
      log "Fatal Error" at FATAL; // log level is FATAL
      log "Critical Error" at CRIT; // log level is CRITICAL
      log "Warning" at WARN; // log level is WARNING
   }
}
```

Apama-ctrl analyzes all the log messages, filters out only certain log messages, and raises an alarm for the identified ones. Thus, Apama-ctrl generates the following three alarms for the above example:

First alarm:

- Alarm type: `APAMA_CTRL_FATAL_<HASHCODE>`
- Alarm text: &lt;Monitor name&gt;-Fatal Error.
- Alarm severity: MAJOR

Second alarm:

- Alarm type: `APAMA_CTRL_CRIT_<HASHCODE>`
- Alarm text:&lt;Monitor name&gt;-Critical Error.
- Alarm severity: MAJOR

Third alarm:

- Alarm type: `APAMA_CTRL_WARN_<HASHCODE>`
- Alarm text: &lt;Monitor name&gt;-Warning.
- Alarm severity: WARNING


#### An EPL file throws an uncaught exception {#apama_ctrl_error}

You have seen that the Apama-ctrl microservice raises alarms for logged messages. In addition, there can also be uncaught exceptions (during runtime). Apama-ctrl identifies such exceptions and raises alarms so that you can identify and fix the problem.

For example, the following monitor throws `IndexOutOfBoundsException` during runtime:

```java
monitor Sample{
   sequence<string> values := ["10", "20", "30"];
   action onload() {
      // IndexOutOfBoundsException (runtime error)
      log "Value = " + values[10] at ERROR;
   }
}
```

Apama-ctrl generates the following alarm for the above example:

- Alarm type: `APAMA_CTRL_ERROR_<HASHCODE>`
- Alarm text: &lt;Monitor name&gt;-Error on line &lt;x&gt; of monitor : IndexOutOfBoundsException - Out of bounds index passed to sequence [] operator - Sample
- Alarm severity: MAJOR

You can diagnose the issue by the monitor name and line number given in the alarm.

For more details, you can also check the log files of the Apama-ctrl microservice if the tenant has the "microservice hosting" feature enabled. Alarms of this type should be fixed as a priority as these uncaught exceptions will terminate the execution of that monitor instance, which will typically mean that your app is not going to function correctly. This might even lead to a correlator crash if not handled properly. See also [Log files of the Apama-ctrl microservice](#logfiles).


#### An EPL app is running in an infinite or long-running loop {#apama_ctrl_warn}

If an EPL app has an infinite or long-running loop, it may block the correlator context for too long, not letting any other apps run in the same context or, even worse, causes excessive memory usage (as the correlator is unable to perform any garbage collection cycles) leading to the app running out of memory. The Apama-ctrl microservice identifies such scenarios (the correlator logs warning messages if an app is blocking a context for too long) and raises alarms, so that the user can identify and fix the problem.

For example, the following monitor blocks the correlator main context:

```java
event MyEvent {
}

monitor Sample{
    action onload() {
        while true {
            // do something
            send MyEvent() to "foo";
        }
    }
}
```

Apama-ctrl generates the following alarm for the above example:

- Alarm type: `APAMA_CTRL_WARN_<HASHCODE>`
- Alarm text: &lt;EPLAppName&gt;.&lt;monitorName&gt; - This EPL app is probably in an infinite or long-running loop and impedes the operation of your other apps. It is recommended that you deactivate and diagnose this app.
- Alarm severity: WARNING

You can diagnose the issue by the monitor name given in the alarm.

For more details, you can also check the log files of the Apama-ctrl microservice if the tenant has the "microservice hosting" feature enabled. Alarms of this type should be fixed as a priority as these scenarios may lead to the microservice and correlator running out of memory. See also [Log files of the Apama-ctrl microservice](#logfiles).


#### EPL app restore timeout on restart of Apama-ctrl {#eplapp_restore_timeout}

If restoring an EPL app on a restart of the Apama-ctrl microservice takes a long time and exceeds the time limit
specified by the `recovery.timeoutSecs` tenant option (in the `streaminganalytics` category) or a default of 60 seconds,
the Apama-ctrl microservice times out and raises an alarm, indicating that it will restart and reattempt to restore the EPL app.
The alarm text includes the names of any EPL apps that are considered to be the reason for the timeout.

- Alarm type: `eplapp_restore_timeout`
- Alarm text: Restoring EPL apps after Apama-ctrl microservice restart has timed out. The EPL app &lt;app name&gt; could not be restored.
The following EPL apps may be the cause of this: &lt;comma-separated list of app names&gt;.
The Apama-ctrl microservice will restart now, and restoring will be reattempted.
If this continues to fail, the Apama-ctrl microservice will enter safe mode, disabling all EPL apps.
- Alarm severity: MAJOR

The following information is only included in the alarm text if the Apama-ctrl microservice detects that the timeout is due to some EPL apps:
"The following EPL apps may be the cause of this: &lt;comma-separated list of app names&gt;.".
If no such apps are detected, this information is omitted from the alarm text.


#### Multiple extensions with the same name {#extension_error}

This alarm is raised when the Apama-ctrl microservice tries to activate the deployed extensions during its startup process and there are multiple extensions with the same name.

- Alarm type: `extension_error`
- Alarm text: Multiple extensions with the same name have been found: &lt;list of all duplicate extension names&gt;
- Alarm severity: CRITICAL

This disables all extensions that were deployed to Apama-ctrl. In order to use the deployed extensions, the user must decide which extensions to keep and then delete the duplicate ones.

{{< c8y-admon-info >}}
In case of multiple duplicates, this alarm is only listed once.
{{< /c8y-admon-info >}}


#### Smart rule configuration failed {#smart-rule-configuration-failed}

This alarm is raised if a smart rule contains an invalid configuration.

- Alarm type: `smartrule_configuration_error`
- Alarm text: &lt;Smart rule identifier&gt;: Smart rule create/edit failed. One or more fields are invalid, please check smart rule configuration.
- Alarm severity: MAJOR

To diagnose the cause, download the diagnostics overview ZIP file as described in [Downloading diagnostics and logs](#diagnostics-download). Or, if that fails, log on as an administrator and look at the result of a GET request to */service/smartrule/smartrules?withPrivateRules=true*. Review the smart rules JSON and look for invalid smart rule configurations. Such smart rules must be corrected.

The Apama microservice log contains more details on the reason for the smart rule configuration failure. For example, it is invalid to configure an "On measurement threshold create alarm" smart rule with a data point that does not exist.

#### Smart rule restore failed {#smart-rule-restore-failed}

This alarm is raised if a corrupt smart rule is present in the inventory and the correlator therefore fails to recover it correctly during startup.

- Alarm type: `smartrule_restore_failed`
- Alarm text: Smart rule restore failed. Contact support.
- Alarm severity: MAJOR

To diagnose the cause, download the diagnostics overview ZIP file as described in [Downloading diagnostics and logs](#diagnostics-download). Or, if that fails, log on as an administrator and look at the result of a GET request to */service/smartrule/smartrules?withPrivateRules=true*. Review the smart rules JSON and look for invalid smart rule configurations. Such smart rules may need to be deleted or corrected.

#### Connection to correlator lost {#connection-to-correlator-lost}

This alarm is raised in certain cases when the connection between the Apama-ctrl microservice and the correlator is lost. This should not happen, but can be triggered by high load situations.

- Alarm type: `lost_correlator_connection`
- Alarm text: Unable to ping correlator: &lt;message&gt;, Apama-ctrl will restart.
- Alarm severity: MAJOR

Apama-ctrl will automatically restart. Report this to [product support](/additional-resources/contacting-support/) if this is happening frequently.


#### Performance alarms {#performance-alarms}

Input or output queues that are filling up are a symptom of a serious performance degradation,
suggesting that events or requests are being produced by Apama or {{< product-c8y-iot >}} faster than they can be processed by Apama or {{< product-c8y-iot >}}.

The performance of the correlator's input and output queues is periodically monitored.
Different types of alarms can be raised, where the alarm text contains a snapshot of the correlator status at the time of raising the alarm.

This alarm is raised for the input queues:

- Alarm type: `input_queues_filling`
- Alarm text: Correlator input queues are filling. If this alarm is being regularly raised, there is a chance that the correlator
  cannot process the requests at the rate at which they are arriving.
  Slowest receiver name: &lt;name&gt;,
  Slowest receiver queue size: &lt;size&gt;,
  Slowest context name: &lt;name&gt;,
  Slowest context queue size: &lt;size&gt;.
- Alarm severity: WARNING

This alarm is raised for the output queues:

- Alarm type: `output_queues_filling`
- Alarm text: Correlator output queues are filling. If this alarm is being regularly raised, there is a chance that {{< product-c8y-iot >}}
  is not able to process the requests at the rate the correlator is sending them.
  Slowest receiver name: &lt;name&gt;,
  Slowest receiver queue size: &lt;size&gt;,
  Slowest context name: &lt;name&gt;,
  Slowest context queue size: &lt;size&gt;.
- Alarm severity: WARNING

This alarm is raised for both the input and output queues:

- Alarm type: `input_output_queues_filling`
- Alarm text: Correlator input and output queues are filling. If this alarm is being regularly raised, there is a chance that {{< product-c8y-iot >}}
  is not able to process the requests at the rate the correlator is sending them, causing the slowest output queue to fill up.
  This might have also caused the slowest input queue to fill up.
  Slowest receiver name: &lt;name&gt;,
  Slowest receiver queue size: &lt;size&gt;,
  Slowest context name: &lt;name&gt;,
  Slowest context queue size: &lt;size&gt;.
- Alarm severity: MAJOR

See also [List of correlator status statistics]({{< link-apama-webhelp >}}index.html#page/pam-webhelp%2Fre-DepAndManApaApp_list_of_correlator_status_statistics.html) in the Apama documentation.

Check the text from the above alarms to get an indication of which queue is blocking.
A problem is likely to trigger these alarms, followed by this alarm:

- Alarm text: Real-time event processing is currently overloaded and may stop processing your events. Please contact support.
- Alarm severity: CRITICAL

This alarm is raised whenever the CEP queue for the respective tenant is full.
It is coming from {{< product-c8y-iot >}} Core, but concerns Apama-ctrl.

Karaf nodes that send events to the CEP engine maintain per-tenant queues for the incoming events. This data gets processed by the CEP engine for the hosted CEP rules. For various reasons, these queues can become full and cannot accommodate newly arriving data. In such cases, an alarm is sent to the platform so that the end users are notified about the situation.

If the CEP queue is full, older events are removed to handle new incoming events. To avoid this, you must diagnose the cause of the queue being full and resolve it as soon as possible.

The CEP queue size is based on the number of CEP events, not raw bytes.

To diagnose the cause, you can try the following. It may be that the Apama-ctrl microservice is running slow because of time-consuming smart rules, analytic models or EPL apps, or the microservice is deprived of resources, or code is not optimized, and so on. Check the correlator input and output queues from the above alarms (or from the microservice logs or from the diagnostics overview ZIP file under */correlator/status.json*).

- If both input and output queues are full, this suggests a slow receiver, possibly EPL sending too many requests (or too expensive a request) to {{< product-c8y-iot >}}.
- Else, if only the input queue is full, EPL is probably running in a tight loop. Try analyzing the *cpuProfile.csv* output in the diagnostic overview ZIP file, especially the monitor name and CPU time. The data collected in the profiler may also help in identifying other possible bottlenecks. For details, refer to [Using the CPU profiler]({{< link-apama-webhelp >}}index.html#page/pam-webhelp%2Fta-DepAndManApaApp_using_the_cpu_profiler.html) in the Apama documentation.
- Else, the cause may be some issue with connectivity or in {{< product-c8y-iot >}} Core.


#### Parent tenant not subscribed {#parent-tenant-not-subscribed}

This alarm is raised for a subtenant that was subscribed before the parent tenant was subscribed.

- Alarm type: `parent_tenant_not_subscribed`
- Alarm text: The microservice cannot function fully until the parent tenant is also subscribed to the microservice. Please contact the administrator.
- Alarm severity: MAJOR

The Apama-ctrl microservice allows you to subscribe to tenants in any order.
However, as long as the parent tenant is not subscribed, the microservice functionality will not work on the subtenant.

This alarm is cleared once the parent tenant is subscribed.
